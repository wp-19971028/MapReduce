# MapReduce计算模型的介绍

## MapReduce的思想

> MapReduce的思想在我们生活中处处可见.其核心思想是**分而治之**适用大量复杂的任务处理场景（大规模数据处理场景）.

> map**负责"分 "**，即把复杂的任务分解为若干个“简单的任务”来并行处理。可以进行拆分的前提是这些小任务可以并行计算，彼此间几乎没有依赖关系。
>
> reduce**负责“合”**，即对map阶段的结果进行全局汇总。

> 比如说：需求  从1 + 2 + 3 + 4 .... + 10000 如何计算呢？
>
> - 单机程序： 每个数字的累加计算。
> - 分布式，分而治之思想：
>   - 先找十个人，10个计算器，来进行计算操作	
>   - 第一个人拿走：1  + 2 + ... + 1000
>   - 第二个人拿走：1001 + 1002 + ... + 2000
>   - 依此类推 ....
>   - 第十个人拿走: 9000 + 9001 +... + 10000
>   - 最终，将这十个计算器计算的结果进行累加操作，得到最终的结果。

##  **Hadoop MapReduce设计构思**

- MapReduce是一个分布式运算程序的编程框架，核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在Hadoop集群上。

- 既然是做计算的框架，那么表现形式就是有个输入（input），MapReduce操作这个输入（input），通过本身定义好的计算模型，得到一个输出（output）。

- 对许多开发者来说，自己完完全全实现一个并行计算程序难度太大，而MapReduce就是一种简化并行计算的编程模型，降低了开发并行应用的入门门槛。

- Hadoop MapReduce构思体现在如下的三个方面：

  -  **如何对付大数据处理：**分而治之

    - > 对相互间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取分而治之的策略。并行计算的第一个重要问题是如何划分计算任务或者计算数据以便对划分的子任务或数据块同时进行计算。不可分拆的计算任务或相互间有依赖关系的数据无法进行并行计算！

  -  **构建抽象模型：Map和Reduce**

    - > MapReduce借鉴了函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型。
      >
      > Map: 对一组数据元素进行某种重复式的处理；
      >
      > Reduce: 对Map的中间结果进行某种进一步的结果整理。
      >
      > MapReduce中定义了如下的Map和Reduce两个抽象的编程接口，由用户去编程实现:
      >
      > **map: (k1; v1) → [(k2; v2)]**
      >
      > **reduce: (k2; [v2]) → [(k3; v3)]**
      >
      > Map和Reduce为程序员提供了一个清晰的操作接口抽象描述。通过以上两个编程接口，大家可以看出MapReduce处理的数据类型是<key,value>键值对。

  - MapReduce核心功能：

    - 将用户编写的**业务逻辑**代码和MapReduce本身自带的组件整合到一个完整的分布式计算程序。

      ![image-20200822102926936](./assets\image-20200822102926936.png)

  - block 数据分块，是hdfs中的概念，物理上进行数据的分割，（默认128M）分成一个数据块，split是mapreduce中的一个逻辑的概念，mapTask处理数据的一个分片，具体怎么分片，是和 InputFormat。每个分片对应的是一个map任务。

## MapReduce编程规范及示例编写

> MapReduce 的开发一共有八个步骤(俗称天龙八部), 其中 Map 阶段分为2个步骤，Shuffle 阶段 4 个步骤，Reduce 阶段分为2个步骤

- map阶段的两步

  1. 设置 InputFormat 类, 读取输入文件内容，对输入文件的每一行，解析成key、value对（K1和V1）。
  2. 自定义map方法，每一个键值对调用一次map方法，将第一步的K1和V1结果转换成另外的 Key-Value（K2和V2）对, 输出结果。


![image-20200822105626069](./assets\image-20200822105626069.png)

- **Shuffle 阶段 4 个步骤**

  3. 对map阶段输出的k2和v2对进行分区

  4. 对不同分区的数据按照相同的Key排序
  5. (可选)对数据进行局部聚合, 降低数据的网络拷贝
  6.  对数据进行分组, 相同Key的Value放入一个集合中,得到K2和[V2]

![image-20200822105611233](./assets\image-20200822105611233-1620307756051.png)

- **Reduce 阶段 2 个步骤**
  7. 对map任务的输出，按照不同的分区，通过网络copy到不同的reduce节点。
  8. 对多个map任务的输出进行合并、排序。编写reduce方法，在此方法中将K2和[V2]进行处理，转换成新的key、value(K3和V3)输出，并把reduce的输出保存到文件中。

![image-20200822105953130](./assets\image-20200822105953130.png)

## **编程步骤:**

用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)

### **Mapper**

- 自定义类继承Mapper类

- 重写自定义类中的map方法，在该方法中将K1和V1转为K2和V2
-  将生成的K2和V2写入上下文中

 

### **Reducer**

- 自定义类继承Reducer类

- 重写Reducer中的reduce方法，在该方法中将K2和[V2]转为K3和V3

- 将K3和V3写入上下文中

 

### **Driver**

整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象

- 定义类，编写main方法

- 在main方法中指定以下内容:
  1. 创建建一个job任务对象
  2. 指定job所在的jar包
  3. 指定源文件的读取方式类和源文件的读取路径
  4. 指定自定义的Mapper类和K2、V2类型
  5. 指定自定义分区类（如果有的话）
  6. 指定自定义分组类（如果有的话）
  7. 指定自定义的Reducer类和K3、V3的数据类型
  8. 指定输出方式类和结果输出路径
  9. 将job提交到yarn集群